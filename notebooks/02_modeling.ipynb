{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed/train_data.csv\", index_col = 0)\n",
    "df_val = pd.read_csv(\"../data/processed/validation_data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep Classs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepDataset():\n",
    "\n",
    "    def __init__(self, df : pd.DataFrame, df_name : str, ohe_cutoff : int = 20, outliers : str = None,\n",
    "                 cols_to_remove : list = [\"step\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"]):\n",
    "        \n",
    "        valid_names = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "        if df_name not in valid_names:\n",
    "            raise ValueError(f\"invalid df_name : {df_name}, use one of {valid_names}\")\n",
    "        \n",
    "        self.df_name = df_name\n",
    "\n",
    "        self.df = df\n",
    "        self.df_orginal = df.copy()\n",
    "\n",
    "        self.remove_columns(col_list = cols_to_remove)\n",
    "\n",
    "        self.encode_categoriacals(ohe_cutoff = ohe_cutoff)\n",
    "\n",
    "        if outliers:\n",
    "            self.replace_outliers(method = outliers)\n",
    "    \n",
    "    def remove_columns(self, col_list : list):\n",
    "        \"\"\"\n",
    "        This function drops a list of columns from \n",
    "        the dataframe.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df.drop(col_list, axis = 1, inplace = True)\n",
    "    \n",
    "    def encode_categoriacals(self, ohe_cutoff : int = 20, mappings_save_path : str = \"../data/other/\"):\n",
    "        \"\"\"\n",
    "        This function encodes the categorical columns so they can be feed into \n",
    "        a model. The parameter ohe_cutoff divides the columns into two lists. The \n",
    "        first list, containing less unique values per column than then the parameter, will store \n",
    "        the column names that will be one hot encoded. The second list, conataining more or \n",
    "        equal unique values per column than the parameter, will store the column names that will\n",
    "        be label encoded.\n",
    "        \"\"\"\n",
    "        mappings_save_path += f\"mappings_label_encoding_{self.df_name}.json\"\n",
    "\n",
    "        df_unq_vals = self.df.select_dtypes(include = \"object\").nunique().reset_index().rename({\"index\" : \"col_name\", 0 : \"n_unique_values\"}, axis = 1)\n",
    "        ohe_list = df_unq_vals.loc[df_unq_vals.n_unique_values < ohe_cutoff, \"col_name\"].tolist()\n",
    "        label_enc_list = df_unq_vals.loc[df_unq_vals.n_unique_values >= ohe_cutoff, \"col_name\"].tolist()\n",
    "\n",
    "        # one hot encoding \n",
    "        self.df = pd.get_dummies(data = self.df, columns = ohe_list, dtype = int)\n",
    "        \n",
    "        # label encoding\n",
    "        mappings_label_encoding = {}\n",
    "\n",
    "        for col in label_enc_list:\n",
    "            self.df[col] = self.df[col].astype(\"category\")\n",
    "            mappings_label_encoding[col] = dict(enumerate(self.df[col].cat.categories))\n",
    "\n",
    "            self.df[col] = self.df[col].cat.codes\n",
    "\n",
    "        with open(mappings_save_path, 'w') as f:\n",
    "            json.dump(mappings_label_encoding, f)\n",
    "    \n",
    "    def restore_data(self):\n",
    "        \"\"\"\n",
    "        This function restores the data to the original version before\n",
    "        replacing outliers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = self.original_df.copy()\n",
    "    \n",
    "    def replace_outliers(self, method : str = \"z_score\"):\n",
    "        \"\"\"\n",
    "        This function substitutes outliers with the border value \n",
    "        according to which method chosen.\n",
    "        \"\"\"\n",
    "        \n",
    "        valid_methods = [\"z_score\", \"iqr\", \"both\"]\n",
    "\n",
    "        if method not in valid_methods:\n",
    "            raise ValueError(f\"invalid method : {method}, use one of {valid_methods}\")\n",
    "        \n",
    "        col_outliers = self.df.select_dtypes(include = \"float\").columns.tolist()\n",
    "\n",
    "        for col in col_outliers:\n",
    "            mean = self.df[col].mean()\n",
    "            std = self.df[col].std()\n",
    "\n",
    "            self.df[\"z_score\"] = (self.df[col] - mean) / std\n",
    "            zscore_upper_bound = self.df[self.df.z_score <= 3].sort_values(by = \"amount\", ascending = False)[\"amount\"].head(1).values[0]\n",
    "            zscore_lower_bound = self.df[self.df.z_score >= -3].sort_values(by = \"amount\")[\"amount\"].head(1).values[0]\n",
    "            self.df.drop(\"z_score\", axis = 1, inplace = True)\n",
    "\n",
    "            q1 = self.df[col].quantile(0.25)\n",
    "            q3 = self.df[col].quantile(0.75)\n",
    "            iqr = q3 - q1 \n",
    "\n",
    "            iqr_upper_bound = q3 + 1.5 * iqr\n",
    "            iqr_lower_bound = q1 - 1.5 * iqr\n",
    "\n",
    "            if method == \"both\":\n",
    "                upper_bound  = min(zscore_upper_bound, iqr_upper_bound)\n",
    "                lower_bound = max(zscore_lower_bound, iqr_lower_bound)\n",
    "            \n",
    "            elif method == \"z_score\":\n",
    "                upper_bound  = zscore_upper_bound\n",
    "                lower_bound = zscore_lower_bound\n",
    "            \n",
    "            elif method == \"iqr\":\n",
    "                upper_bound  = iqr_upper_bound\n",
    "                lower_bound = iqr_lower_bound\n",
    "            \n",
    "            if len(self.df[self.df.amount > upper_bound]) > 0:\n",
    "                    self.df.loc[self.df.amount > upper_bound, \"amount\"] = upper_bound\n",
    "                \n",
    "            if len(self.df[self.df.amount < lower_bound]) > 0:\n",
    "                self.df.loc[self.df.amount < lower_bound, \"amount\"] = lower_bound\n",
    "\n",
    "    def return_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function returns the dataframe.\n",
    "        \"\"\"  \n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Models Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicModelsEvaluation():\n",
    "\n",
    "    def __init__(self, df_train : pd.DataFrame, df_val : pd.DataFrame, df_eval : pd.DataFrame, imbalance : str,\n",
    "                  outliers : str, target : str = \"isFraud\"):\n",
    "        self.df_train  = df_train\n",
    "        self.df_val = df_val\n",
    "\n",
    "        self.df_eval = df_eval\n",
    "\n",
    "        self.imbalance = imbalance\n",
    "        self.outliers = outliers\n",
    "\n",
    "        self.x_train, self.y_train = self.split_x_y(df = self.df_train, target = target)\n",
    "        self.x_val, self.y_val = self.split_x_y(df = self.df_val, target = target)\n",
    "\n",
    "        self.evaluate_model(model = LogisticRegression(n_jobs = -1, random_state = seed), model_name = \"logistic regression\")\n",
    "        self.evaluate_model(model = RandomForestClassifier(n_jobs = -1, random_state = seed), model_name = \"random forest\")\n",
    "        self.evaluate_model(model = XGBClassifier(n_jobs = -1, random_state = seed), model_name = \"xgb\")\n",
    "\n",
    "    def split_x_y(self, df : pd.DataFrame, target : str) -> tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        This function splits a dataframe in x (the dataframe containing the predictors) and\n",
    "        y (the series witht the target)\n",
    "        \"\"\"\n",
    "\n",
    "        predictors = df.columns.tolist()\n",
    "        predictors.remove(target)\n",
    "\n",
    "        x = df[predictors]\n",
    "        y = df[target]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def evaluate_model(self, model, model_name : str):\n",
    "        \"\"\"\n",
    "        This function first trains the model on the training data contained in the class, and \n",
    "        then evaluates it using both the training data and the validation data, also present in the\n",
    "        class. The results are then stored in the df_eval.\n",
    "        \"\"\"\n",
    "\n",
    "        # training the model\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        # computing predictions\n",
    "        y_pred_train = model.predict(self.x_train)\n",
    "        y_pred_val = model.predict(self.x_val)\n",
    "        \n",
    "        # calculating metrics\n",
    "        accuracy_train = skm.accuracy_score(y_pred = y_pred_train, y_true = self.y_train)\n",
    "        recall_train = skm.recall_score(y_pred = y_pred_train, y_true = self.y_train)\n",
    "        precision_train = skm.precision_score(y_pred = y_pred_train, y_true = self.y_train)\n",
    "        f1_score_train = skm.f1_score(y_pred = y_pred_train, y_true = self.y_train)\n",
    "\n",
    "        accuracy_val = skm.accuracy_score(y_pred = y_pred_val, y_true = self.y_val)\n",
    "        recall_val = skm.recall_score(y_pred = y_pred_val, y_true = self.y_val)\n",
    "        precision_val = skm.precision_score(y_pred = y_pred_val, y_true = self.y_val)\n",
    "        f1_score_val = skm.f1_score(y_pred = y_pred_val, y_true = self.y_val)\n",
    "\n",
    "        # saving results\n",
    "        self.df_eval.loc[len(self.df_eval)] = {\n",
    "            \"imbalance\" : self.imbalance,\n",
    "            \"outliers\" : self.outliers,\n",
    "            \"model\" : model_name, \n",
    "            \"dataset\" : \"train\", \n",
    "            \"accuracy\" : accuracy_train,\n",
    "            \"recall\" : recall_train, \n",
    "            \"precision\" : precision_train, \n",
    "            \"f1_score\" : f1_score_train}\n",
    "\n",
    "        self.df_eval.loc[len(self.df_eval)] = {\n",
    "            \"imbalance\" : self.imbalance,\n",
    "            \"outliers\" : self.outliers,\n",
    "            \"model\" : model_name, \n",
    "            \"dataset\" : \"validation\", \n",
    "            \"accuracy\" : accuracy_val,\n",
    "            \"recall\" : recall_val, \n",
    "            \"precision\" : precision_val, \n",
    "            \"f1_score\" : f1_score_val}\n",
    "        \n",
    "    def return_df_eval(self):\n",
    "        \"\"\"\n",
    "        This function retuns the df eval.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance</th>\n",
       "      <th>outliers</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [imbalance, outliers, model, dataset, accuracy, recall, precision, f1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(columns = [\"imbalance\", \"outliers\", \"model\", \"dataset\", \"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_train = PrepDataset(df = df_train, df_name = \"train\")\n",
    "df_train = data_prep_train.return_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_val = PrepDataset(df = df_val, df_name = \"validation\")\n",
    "df_val = data_prep_val.return_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classsic_model_eval = ClassicModelsEvaluation(df_train = df_train, df_val = df_val, df_eval = df_eval, imbalance = \"none\", outliers = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbalance</th>\n",
       "      <th>outliers</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>train</td>\n",
       "      <td>0.998697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>random forest</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>random forest</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.998853</td>\n",
       "      <td>0.157638</td>\n",
       "      <td>0.773134</td>\n",
       "      <td>0.261881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>xgb</td>\n",
       "      <td>train</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.103322</td>\n",
       "      <td>0.665174</td>\n",
       "      <td>0.178862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>xgb</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.998744</td>\n",
       "      <td>0.090079</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>0.156283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imbalance outliers                model     dataset  accuracy    recall  \\\n",
       "0      none     none  logistic regression       train  0.998697  0.000000   \n",
       "1      none     none  logistic regression  validation  0.998696  0.000000   \n",
       "2      none     none        random forest       train  0.999997  0.997391   \n",
       "3      none     none        random forest  validation  0.998853  0.157638   \n",
       "4      none     none                  xgb       train  0.998775  0.103322   \n",
       "5      none     none                  xgb  validation  0.998744  0.090079   \n",
       "\n",
       "   precision  f1_score  \n",
       "0   0.000000  0.000000  \n",
       "1   0.000000  0.000000  \n",
       "2   1.000000  0.998694  \n",
       "3   0.773134  0.261881  \n",
       "4   0.665174  0.178862  \n",
       "5   0.589641  0.156283  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = classsic_model_eval.return_df_eval()\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
